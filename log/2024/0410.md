# Day1

## Mamba
### 主要收获
mamba相关模型结构初步学习，主要参考如下两个帖子：

**[一文通透想颠覆Transformer的Mamba：从SSM、HiPPO、S4到Mamba](https://blog.csdn.net/v_JULY_v/article/details/134923301)**

**[Mamba详细介绍和RNN、Transformer的架构可视化对比](https://mp.weixin.qq.com/s/eRRBxjliAXAHXDu-LSDs9A)**

Transformer训练快，推理慢；而RNN训练慢，推理快。

SSM（The State Space Model）利用RL中关于状态空间表示的说法，建立了两个方程：状态方程 和 输出方程。

对于输入，首先进入SSM先更新状态，然后新的状态再结合x转换为输出。

SSM建模表示都是基于连续时间，如果要在文本上使用，需要进行离散化表示。可以采用零阶保持技术（zero-order hold，每次收到一个离散信号，都保持值不变，等到下一个新的离散信号再改变），保持一个值的时间可以通过一步 步长 参数来表示，这样就可以使用连续信号并且只根据输入的 时间步长 来进行采样。

SSM可以重新按照RNN的方式进行展开表示，但是推理快，训练慢。

另外一种采用CNN表示的SSM，利用kernel来进行特征聚合，训练快，kernel大小固定推理不如RNN快且对序列长度有限制。

还有一种是训练过程采用CNN，推理过程使用RNN。


SSM公式中比较重要的就是矩阵A，因为需要捕获前一个状态来更新状态，如果和RNN一样的话，也会有遗忘。HiPPO模型结合递归记忆（Recurrent Memory）和最优多项式投影（Optimal Polynomial Projections，通过函数逼近的方式来产生矩阵A的最优解）。

Mamba主要的贡献：选择性扫描算法 和 硬件感知算法。

由于SSM的状态是固定，因此更加有效但是不够强大，而Transformer注意力很强大，但是和序列长度相关，比较低效；因此Mamba需要在这个中间找到一种平衡。

SSM中矩阵A、B、C都是固定的，不随输入变化而变化，因此也就不能针对性的推理。

Mamba希望将数据进行压缩，矩阵B和C以及步长参数，根据序列长度和批量大小（B和C，状态维度从(D,N)变化为(B,L,N)，而步长参数维度(D)变化为(B,L,D)），选择性将什么保留在隐藏状态中，什么需要忽略，都是由输入确定的。

较小的步长忽略特定的词，更多使用之前的长下文，较大的步长则更加关注输入而不是上下文。


循环处理不能进行并行化主要原因是由于每个隐藏状态都需要依赖前一状态，Mamba使用并行化扫描算法，计算部分序列并迭代组合。


### 主要疑惑
1、SSM为什么不能一开始使用离散信号？
* 最开始使用在时间序列分析上的统计模型，使用连续信号而不是离散信号主要考虑到物理过程真实性、数学处理便利性、模型平滑性、预测准确性、系统稳定性等等。

2、步长参数具体的作用是什么？
* 较大的步长意味着时间分辨率低，计算量和模型复杂度低（更少的数据点），减少噪声的影响，数据更加平滑；较小的步长意味着时间分辨率高，计算量和模型复杂度高，能够捕捉到更细微的变化。
* 更复杂或是非线性的场景下，选择合适的步长就比较困难，因此把步长作为一个模型可学习的参数，通过训练阶段反向传播和梯度下降不断调整，来更好的适应数据的动态变化，提高模型预测精度。

3、扫描性算法为什么可以并行？
* 分段 & 迭代计算的方式最终组合，类似于map-reduce？但是还没有仔细推导。

4、类似Flash Attention的硬件感知算法具体是什么？
* 利用内存的不同层级处理SSM的状态，减少GPU HBM与SRAM之间的交互次数。从HBM中加载参数到SRAM上，然后进行离散化、扫描以及最终的输出计算，然后再拷贝到HBM中。

### 遗留问题
1、HiPPO中关于采用函数逼近产生最优矩阵A，具体原理是什么？